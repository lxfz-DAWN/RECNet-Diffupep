{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import datetime\n",
    "import csv\n",
    "import pandas as pd\n",
    "from Bio.PDB.PDBParser import PDBParser\n",
    "from Bio.PDB import Selection, PDBIO\n",
    "\n",
    "# Load the config JSON file\n",
    "config_path = \"/home/users/hcdai/AI-peptide/RunRosetta/config.json\"\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "workspace = config[\"workspace\"]\n",
    "rosetta_path = config[\"rosetta\"]\n",
    "\n",
    "os.chdir(workspace)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     receptor_chain ligand_chain Unnamed: 3\n",
      "PDB                                        \n",
      "1a22              A            B           \n",
      "1a2k            A,B            C           \n",
      "1a4y              A            B           \n",
      "1acb              I            E           \n",
      "1ak4              D            A           \n"
     ]
    }
   ],
   "source": [
    "# 读取pdb文件的索引信息\n",
    "pdb_index = pd.read_csv(config['pdb_index'], index_col=0)\n",
    "print(pdb_index.head())\n",
    "# ab = pdb_index.loc['1wej'][\"ligand_chain\"].split(';')\n",
    "# print(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义待处理的pdb文件的生成器\n",
    "\n",
    "pdb_dir = config['input']\n",
    "pdb_file_list = os.listdir(pdb_dir)\n",
    "pdb_file_num = len(pdb_file_list)\n",
    "\n",
    "def pdb_generator():\n",
    "    \"pdb文件生成器，用于input文件夹中读取pdb文件，仅限后缀为.pdb的文件\"\n",
    "    for i in range(pdb_file_num):\n",
    "        pdb_file:str = os.path.join(pdb_dir, pdb_file_list[i])\n",
    "        if os.path.isfile(pdb_file) and pdb_file.endswith('.pdb'):\n",
    "            yield pdb_file\n",
    "        else:\n",
    "            print(f\"{pdb_file} is not a valid pdb file.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('6uvo',\n",
       " {'L': 'EIVMTQSPATLSVSPGERATLSCRASQSVNSNLAWYQHKPGQAPRLLIYGASTRATGIPARFSGSGSGTDFTLTISSLQSEDFAVYYCQQYNNWPLFGPGTKVDLKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGE',\n",
       "  'H': 'QLQLQESGPGLVKPSETLSLTCTVSGGSISSSNYYWGWIRQPPGKGLEWIASIHDSGSIYYNPSLRSRVTISVDTSKNQFSLKLSSVTAADTAVYYCARHLVWFGELRNNWFDPWGQGTLVTVASASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPKSCD'},\n",
       " {'D': 'NNDFHFEVFNFVPCSICSNNPTCWAICKRI'})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义pdb文件处理的函数\n",
    "\n",
    "def pdb_parser(pdb_file: str):\n",
    "    \"\"\"\n",
    "    解析pdb文件，返回序列等信息\n",
    "    \"\"\"\n",
    "\n",
    "    # 获取pdb文件的名字\n",
    "    pdb_name = '.'.join(pdb_file.split('/')[-1].split('.')[:-2])\n",
    "    # print(pdb_name)\n",
    "\n",
    "    # 检测pdb_name是否在pdb_index中\n",
    "    if pdb_name not in pdb_index.index:\n",
    "        print(f\"{pdb_name} not in pdb_index\")\n",
    "        return pdb_name\n",
    "\n",
    "\n",
    "    receptor_chain:list = pdb_index.loc[pdb_name][\"receptor_chain\"].replace(\" \",\"\").split(',')\n",
    "    ligand_chain:list = pdb_index.loc[pdb_name][\"ligand_chain\"].replace(\" \",\"\").split(',')\n",
    "    # print(ligand_chain)\n",
    "\n",
    "\n",
    "    # 定义pdb对象（解析器）\n",
    "    parser = PDBParser(PERMISSIVE=1) # PERMISSIV 标签表示一些与PDB文件相关的问题会被忽略（注意某些原子和/或残基会丢失）。\n",
    "    # parser = PDBParser(PERMISSIVE=0) # PERMISSIV 标签表示一些与PDB文件相关的问题会被忽略（注意某些原子和/或残基会丢失）。\n",
    "    structure = parser.get_structure(pdb_name, pdb_file)\n",
    "\n",
    "    # 从pdb对象中选取特定的链，并解析其序列\n",
    "\n",
    "\n",
    " \n",
    "    # 定义氨基酸三个字符映射方式\n",
    "    mapping = {'ALA': 'A', \n",
    "               'ARG': 'R', \n",
    "               'ASN': 'N', \n",
    "               'ASP': 'D', \n",
    "               'CYS': 'C', \n",
    "               'GLN': 'Q', \n",
    "               'GLU': 'E', \n",
    "               'GLY': 'G', \n",
    "               'HIS': 'H', \n",
    "               'ILE': 'I', \n",
    "               'LEU': 'L', \n",
    "               'LYS': 'K', \n",
    "               'MET': 'M', \n",
    "               'PHE': 'F', \n",
    "               'PRO': 'P', \n",
    "               'SER': 'S', \n",
    "               'THR': 'T', \n",
    "               'TRP': 'W', \n",
    "               'TYR': 'Y', \n",
    "               'VAL': 'V',\n",
    "               'ACE': ''}\n",
    "    \n",
    "    # 初始化序列\n",
    "    receptor_seq = {}\n",
    "    ligand_seq = {}\n",
    "\n",
    "    for r in receptor_chain:\n",
    "        for model in structure:\n",
    "            for chain in model:\n",
    "                if chain.get_id() == r:\n",
    "                    receptor_seq.update({r:''.join([mapping.get(item,'') for item in [residue.get_resname().strip() for residue in chain]])})\n",
    "                    # print(chain)\n",
    "    for l in ligand_chain:\n",
    "        for model in structure:\n",
    "            for chain in model:\n",
    "                if chain.get_id() == l:\n",
    "                    ligand_seq.update({l:''.join([mapping.get(item,'') for item in [residue.get_resname().strip() for residue in chain]])})\n",
    "                # print(l)\n",
    "                    \n",
    "                    \n",
    "\n",
    "    return pdb_name , ligand_seq , receptor_seq  \n",
    "\n",
    "pdb_parser('/home/users/hcdai/AI-peptide/RunRosetta/input/pdb_data/6uvo.ent.pdb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosetta_score_changed(pdb_file_path, output_dir, rosetta_path:dict = rosetta_path, receptor_chain:list = ['A', 'B', 'C']):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)  \n",
    "    \n",
    "    print(\"Running Rosetta scoring\")\n",
    "    \n",
    "\n",
    "    # 执行命令的函数\n",
    "    def run_command(command):\n",
    "        result = subprocess.run(command, shell=True, check=True, text=True, capture_output=True)\n",
    "        return result.stdout\n",
    "    \n",
    "    rosetta_temp_path = os.path.join(config[\"temp\"])\n",
    "    if not os.path.exists(rosetta_temp_path):\n",
    "        os.makedirs(rosetta_temp_path)\n",
    "    scorefile_path = os.path.join(output_dir, \"scores.sc\")\n",
    "    if os.path.exists(scorefile_path):\n",
    "        os.remove(scorefile_path)\n",
    "\n",
    "    ori_path = os.getcwd()\n",
    "    # 下策：改变工作路径\n",
    "    os.chdir(rosetta_temp_path)\n",
    " \n",
    "    # 对输入文件进行打分\n",
    "    score_command = f\"{rosetta_path['score_executable']} -s {pdb_file_path} -no_optH false -ignore_unrecognized_res -out:pdb\"\n",
    "    print(score_command)\n",
    "    run_command(score_command)\n",
    "    print(\"Rosetta score_command successful.\")\n",
    "\n",
    "    # 将rosetta_temp_path中打分后的文件重命名，为原名称后面加上\"_scored\"\n",
    "    pdb_files:list = [f for f in os.listdir(rosetta_temp_path) if f.endswith(\".pdb\")] # type: ignore\n",
    "    for pdb_file in pdb_files:\n",
    "        os.rename(os.path.join(rosetta_temp_path, pdb_file),\n",
    "                   os.path.join(rosetta_temp_path, \n",
    "                                pdb_file.replace(\".pdb\", \"_scored.pdb\")))    \n",
    "        \n",
    "    print(\"rename successful.\")\n",
    "    print(output_dir)\n",
    "\n",
    "    # 从rosetta_temp_path中逐条读取文件相对路径，进行接口分析，分析结果保存至output_dir中下以ligand_name命名的文件夹中\n",
    "    for pdb_file in pdb_files:\n",
    "        scored_pdb_file = pdb_file.replace(\".pdb\", \"_scored.pdb\")\n",
    "        scored_pdb_path = os.path.join(rosetta_temp_path, scored_pdb_file)\n",
    "        \n",
    "    # 进行接口分析，输出结果到指定的文件夹\n",
    "    analyze_command = f\"{rosetta_path['InterfaceAnalyzer']} -s {scored_pdb_path} -fixedchains {''.join(receptor_chain)} @{rosetta_path['pack_input_options']}\"\n",
    "    run_command(analyze_command)\n",
    "\n",
    "    print(f\"InterfaceAnalyzer successful for {scored_pdb_file}.\")\n",
    "\n",
    "    # 复制temp文件夹内的所有文件文件到output_dir\n",
    "    for file in os.listdir(rosetta_temp_path):\n",
    "        # if file.endswith(\".pdb\") or file.endswith(\".sc\"):\n",
    "        if file.endswith(\".sc\"):\n",
    "            shutil.copy(os.path.join(rosetta_temp_path, file), os.path.join(output_dir, file))\n",
    "        \n",
    "\n",
    "    # 下策：重新定义回旧工作路径    \n",
    "    os.chdir(ori_path)\n",
    "\n",
    "    print(\"Rosetta scoring successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_add(csv_file_path, score_output_dir, ligand_name, ligand_sequence, receptor_name, receptor_sequence):\n",
    "    '''将分数结果写入csv文件\n",
    "    Args:\n",
    "        csv_file_path: csv文件路径\n",
    "        ligand_name: 配体名称\n",
    "        ligand_sequence: 配体序列\n",
    "        receptor_name: 受体名称\n",
    "        receptor_sequence: 受体序列\n",
    "        score_output_dir: 分数输出文件夹路径\n",
    "    '''\n",
    "    pack_score_path=os.path.join(score_output_dir, \"pack_input_score.sc\")\n",
    "    scores_score_path=os.path.join(score_output_dir, \"score.sc\")\n",
    "    time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "    # 创建目录（如果不存在）\n",
    "    # csv_dir = os.path.dirname(csv_file_path)\n",
    "    # if not os.path.exists(csv_dir):\n",
    "    #     os.makedirs(csv_dir)\n",
    "\n",
    "    # 初始化结果列表\n",
    "    result_list = []\n",
    "\n",
    "    # 读取pack_input_scores.sc文件，获取打分数据\n",
    "    with open(pack_score_path, 'r') as sc_file:\n",
    "            lines = sc_file.readlines()\n",
    "            if len(lines) >= 3:\n",
    "                headers = [f\"pack_{header}\" for header in lines[1].strip().split()[1:]]  # 第二行为表头，去掉第一个，并添加前缀\n",
    "                data = lines[2].strip().split()     # 第三行为数据\n",
    "                # 去掉第一个表头和第一个数据\n",
    "                # headers = headers[1:]\n",
    "                data = data[1:]\n",
    "                # 创建字典存储打分数据\n",
    "                pack_score_data = dict(zip(headers, data))\n",
    "    # 获取scores.sc打分数据\n",
    "    with open(scores_score_path, 'r') as sc_file:\n",
    "        lines = sc_file.readlines()\n",
    "        if len(lines) >= 3:\n",
    "            headers = [f\"scores_{header}\" for header in lines[1].strip().split()[1:]]  # 第二行为表头，去掉第一个，并添加前缀\n",
    "           # 初始化一个字典来存储数据，键为表头，值为空列表\n",
    "        scores_data = {header: [] for header in headers}\n",
    "            # 从第三行开始读取数据（索引为2的行）\n",
    "        for line in lines[2:]:\n",
    "            # 分割每行的数据，并跳过第一个数据（索引为0的元素）\n",
    "            data = line.strip().split()[1:]\n",
    "            \n",
    "            # 检查数据长度是否与表头长度一致\n",
    "            if len(data) != len(headers):\n",
    "                raise ValueError(f\"数据长度 {len(data)} 与表头长度 {len(headers)} 不一致\")\n",
    "            \n",
    "            # 将数据添加到对应的表头列表中\n",
    "            for i, header in enumerate(headers):\n",
    "                scores_data[header].append(data[i])\n",
    "    \n",
    "    # 合并打分数据\n",
    "    merged_scores_data = {**scores_data, **pack_score_data}\n",
    "\n",
    "    result_list.append({\n",
    "        'ligand_name': ligand_name,\n",
    "        'ligand_sequence': ligand_sequence,\n",
    "        'receptor_name': receptor_name,\n",
    "        'receptor_sequence': receptor_sequence, \n",
    "        'time': time,\n",
    "        **merged_scores_data  # 将打分数据作为额外字段添加\n",
    "    })\n",
    "\n",
    "    # 写入csv文件\n",
    "    with open(csv_file_path, mode='a', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = ['ligand_name', 'ligand_sequence', 'receptor_name', 'receptor_sequence','time']\n",
    "        # 添加打分数据的表头\n",
    "        for key in result_list[0].keys():\n",
    "            if key not in fieldnames:\n",
    "                fieldnames.append(key)\n",
    "        \n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        # writer.writeheader()\n",
    "        for row in result_list:\n",
    "            writer.writerow(row)\n",
    " \n",
    "    print(f\"Results have been written to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(config[\"temp\"])\n",
    "    print(\"Cleaned up temp directory.\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# 新建error_pdb.txt文件\n",
    "try:\n",
    "    with open(config[\"error_pdb\"], 'w') as file:\n",
    "        pass\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if not os.path.isfile(config[\"output_csv\"]):\n",
    "    with open(config[\"output_csv\"], mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "            fieldnames = ['ligand_name','ligand_sequence','receptor_name','receptor_sequence','time','scores_total_score','scores_dslf_fa13','scores_fa_atr','scores_fa_dun','scores_fa_elec','scores_fa_intra_rep','scores_fa_intra_sol_xover4','scores_fa_rep','scores_fa_sol','scores_hbond_bb_sc','scores_hbond_lr_bb','scores_hbond_sc','scores_hbond_sr_bb','scores_linear_chainbreak','scores_lk_ball_wtd','scores_omega','scores_overlap_chainbreak','scores_p_aa_pp','scores_pro_close','scores_rama_prepro','scores_ref','scores_yhh_planarity','scores_description','pack_total_score','pack_complex_normalized','pack_dG_cross','pack_dG_cross/dSASAx100','pack_dG_separated','pack_dG_separated/dSASAx100','pack_dSASA_hphobic','pack_dSASA_int','pack_dSASA_polar','pack_delta_unsatHbonds','pack_dslf_fa13','pack_fa_atr','pack_fa_dun','pack_fa_elec','pack_fa_intra_rep','pack_fa_intra_sol_xover4','pack_fa_rep','pack_fa_sol','pack_hbond_E_fraction','pack_hbond_bb_sc','pack_hbond_lr_bb','pack_hbond_sc','pack_hbond_sr_bb','pack_hbonds_int','pack_lk_ball_wtd','pack_nres_all','pack_nres_int','pack_omega','pack_p_aa_pp','pack_packstat','pack_per_residue_energy_int','pack_pro_close','pack_rama_prepro','pack_ref','pack_sc_value','pack_side1_normalized','pack_side1_score','pack_side2_normalized','pack_side2_score','pack_yhh_planarity','pack_description']\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/hcdai/miniconda3/envs/AF3-X/lib/python3.11/site-packages/Bio/PDB/StructureBuilder.py:100: PDBConstructionWarning: WARNING: Chain L is discontinuous at line 4171.\n",
      "  warnings.warn(\n",
      "/home/users/hcdai/miniconda3/envs/AF3-X/lib/python3.11/site-packages/Bio/PDB/StructureBuilder.py:100: PDBConstructionWarning: WARNING: Chain F is discontinuous at line 4172.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Rosetta scoring\n",
      "/home/users/hcdai/AI-peptide/rosetta_interface_analysis/rosetta.binary.ubuntu.release-371/main/source/bin/score_jd2.static.linuxgccrelease -s /home/users/hcdai/AI-peptide/RunRosetta/input/1wej.pdb -no_optH false -ignore_unrecognized_res -out:pdb\n",
      "Rosetta score_command successful.\n",
      "rename successful.\n",
      "/home/users/hcdai/AI-peptide/RunRosetta/output/1wej\n",
      "InterfaceAnalyzer successful for 1wej_0001_scored.pdb.\n",
      "Rosetta scoring successful.\n",
      "Results have been written to /home/users/hcdai/AI-peptide/RunRosetta/output_result.csv\n",
      "Cleaned up temp directory.\n",
      "1ru7 not in pdb_index\n",
      "/home/users/hcdai/AI-peptide/RunRosetta/input/1ru7-lei.cif is not a valid pdb file.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 实例化生成器\n",
    "\n",
    "for pdb_file_path in pdb_generator():\n",
    "    parser = tuple(pdb_parser(pdb_file_path))  \n",
    "\n",
    "    if len(parser) != 3:\n",
    "        # 以追加模式将问题pdb写入error_pdb.txt文件\n",
    "        with open('error_pdb.txt', 'a') as f:\n",
    "            f.write(\"\".join(list(parser)) + '\\n')\n",
    "        continue\n",
    "        \n",
    "    pdb_name, ligand_seq, receptor_seq = parser\n",
    "\n",
    "    output_path = os.path.join(config['output'], pdb_name)\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    # 调用Rosetta的程序\n",
    "    rosetta_score_changed(\n",
    "        pdb_file_path,\n",
    "        output_path,\n",
    "        rosetta_path=config['rosetta'],\n",
    "        receptor_chain = pdb_index.loc[pdb_name][\"receptor_chain\"].split(';')\n",
    "    )\n",
    "\n",
    "    # 写入csv文件\n",
    "    csv_add(\n",
    "        csv_file_path=config['output_csv'],\n",
    "        score_output_dir=output_path,\n",
    "        ligand_name = pdb_name,\n",
    "        ligand_sequence = ligand_seq,\n",
    "        receptor_name = pdb_name,  # !!!!!!!!!!!!!!!!!\n",
    "        receptor_sequence = receptor_seq,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(config[\"temp\"])\n",
    "        print(\"Cleaned up temp directory.\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AF3-X",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
